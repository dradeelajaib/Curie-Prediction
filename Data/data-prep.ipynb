{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f6ec701-f842-4cab-9d5f-2fd4252bd589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adeel\\AppData\\Local\\Temp\\ipykernel_21652\\1696323487.py:5: DtypeWarning: Columns (10,15,16,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"magnetic_materials.csv\")  # Adjust filename if needed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pymatgen.core import Composition\n",
    "\n",
    "# === Load Raw CSV ===\n",
    "df = pd.read_csv(\"magnetic_materials.csv\")  # Adjust filename if needed\n",
    "\n",
    "df = df[['Material_Name', 'Curie']].dropna()\n",
    "\n",
    "def extract_temperature(value):\n",
    "    if pd.isna(value):\n",
    "        return None\n",
    "    try:\n",
    "        # Remove units and parse float from e.g., \"600 K ± 5\", \"580K\", \"298 °C\"\n",
    "        temp_str = str(value).replace(\"K\", \"\")  #.replace(\"°C\", \"\")\n",
    "        return float(temp_str.split()[0])\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "df[\"Temperature_K\"] = df[\"Curie\"].apply(extract_temperature)\n",
    "\n",
    "# === Rename Material column ===\n",
    "df = df.rename(columns={\"Material_Name\": \"Material\"})\n",
    "df_cleaned = df[[\"Material\", \"Temperature_K\"]].dropna()\n",
    "df_cleaned = df_cleaned[(df_cleaned[\"Temperature_K\"] >= 0)]\n",
    "\n",
    "\n",
    "\n",
    "print(len(df_cleaned))\n",
    "\n",
    "\n",
    "df_cleaned.to_csv(\"cleaned_curie_temperatures.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae3f220c-0551-4058-aab4-38d8b30a17a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved deduplicated dataset as 'cleaned_curie_temperatures_deduplicated.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the cleaned dataset\n",
    "df = pd.read_csv(\"cleaned_curie_temperatures.csv\")\n",
    "\n",
    "# Group by the 'Material' column and compute the mean of all numeric columns\n",
    "df_grouped = df.groupby(\"Material\", as_index=False).median(numeric_only=True)\n",
    "\n",
    "# Save the deduplicated dataset\n",
    "df_grouped.to_csv(\"cleaned_curie_temperatures_deduplicated.csv\", index=False)\n",
    "\n",
    "print(\"✅ Saved deduplicated dataset as 'cleaned_curie_temperatures_deduplicated.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f10b5f5-08aa-42ff-8b51-42da4053d5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧪 Parsing elemental fractions: 100%|█████████████████████████████████████████| 14704/14704 [00:00<00:00, 27129.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved to composition_enriched_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pymatgen.core import Composition\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"cleaned_curie_temperatures_deduplicated.csv\")\n",
    "\n",
    "# Parse formulas safely\n",
    "def get_fractional_composition(formula):\n",
    "    try:\n",
    "        comp = Composition(formula)\n",
    "        return comp.fractional_composition.get_el_amt_dict()\n",
    "    except:\n",
    "        return {}\n",
    "\n",
    "# Apply with progress bar\n",
    "tqdm.pandas(desc=\"🧪 Parsing elemental fractions\")\n",
    "fraction_dicts = df[\"Material\"].progress_apply(get_fractional_composition)\n",
    "\n",
    "# Convert to dataframe (element columns)\n",
    "fraction_df = pd.DataFrame(fraction_dicts.tolist()).fillna(0)\n",
    "\n",
    "# Optional: prefix columns to avoid conflicts\n",
    "fraction_df.columns = [f\"el_frac_{el}\" for el in fraction_df.columns]\n",
    "\n",
    "# Merge into main dataframe\n",
    "df_combined = pd.concat([df, fraction_df], axis=1)\n",
    "\n",
    "# Save the new enriched file\n",
    "df_combined.to_csv(\"composition_enriched_dataset.csv\", index=False)\n",
    "print(\"✅ Saved to composition_enriched_dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcc5a8fe-7c90-4209-88dd-1f481c217f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 14704/14704 [00:03<00:00, 4496.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Domain-aware descriptors added and file saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pymatgen.core import Composition, Element\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"composition_enriched_dataset.csv\")  # or your path\n",
    "\n",
    "# Setup tqdm for progress bar\n",
    "tqdm.pandas()\n",
    "\n",
    "# Define magnetic and rare earth elements\n",
    "magnetic_elements = {'Fe', 'Co', 'Ni', 'Mn', 'Cr', 'Gd', 'Tb', 'Dy', 'Ho', 'Er', 'Tm', 'Yb', 'Nd', 'Sm'}\n",
    "rare_earth_elements = {\n",
    "    'La', 'Ce', 'Pr', 'Nd', 'Pm', 'Sm', 'Eu', 'Gd',\n",
    "    'Tb', 'Dy', 'Ho', 'Er', 'Tm', 'Yb', 'Lu'\n",
    "}\n",
    "\n",
    "# Function to compute domain-aware descriptors\n",
    "def compute_domain_props(formula):\n",
    "    try:\n",
    "        comp = Composition(formula)\n",
    "        total = sum(comp.get_el_amt_dict().values())\n",
    "        el_dict = comp.get_el_amt_dict()\n",
    "\n",
    "        mag_prop = sum(el_dict.get(el, 0) for el in magnetic_elements) / total\n",
    "        rare_earth_prop = sum(el_dict.get(el, 0) for el in rare_earth_elements) / total\n",
    "        return pd.Series({\n",
    "            \"Magnetic_proportion\": mag_prop,\n",
    "            \"Rare_Earth_proportion\": rare_earth_prop\n",
    "        })\n",
    "    except:\n",
    "        return pd.Series({\n",
    "            \"Magnetic_proportion\": None,\n",
    "            \"Rare_Earth_proportion\": None\n",
    "        })\n",
    "\n",
    "# Apply the function\n",
    "df[[\"Magnetic_proportion\", \"Rare_Earth_proportion\"]] = df[\"Material\"].progress_apply(compute_domain_props)\n",
    "\n",
    "# Save updated dataset\n",
    "df.to_csv(\"composition_enriched_dataset_with_domain_props.csv\", index=False)\n",
    "print(\"✅ Domain-aware descriptors added and file saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b58de280-da4d-4c37-90a8-fb030c03e74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14704\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"composition_enriched_dataset_with_domain_props.csv\")\n",
    "\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1212d6af-3baf-49a8-af11-877ace8d6621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded dataset: (14704, 104)\n",
      "🔍 Parsing formulas...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 14704/14704 [00:00<00:00, 61268.12it/s]\n",
      "C:\\Users\\Adeel\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n",
      "C:\\Users\\Adeel\\anaconda3\\Lib\\site-packages\\matminer\\utils\\data.py:326: UserWarning: MagpieData(impute_nan=False):\n",
      "In a future release, impute_nan will be set to True by default.\n",
      "                    This means that features that are missing or are NaNs for elements\n",
      "                    from the data source will be replaced by the average of that value\n",
      "                    over the available elements.\n",
      "                    This avoids NaNs after featurization that are often replaced by\n",
      "                    dataset-dependent averages.\n",
      "  warnings.warn(f\"{self.__class__.__name__}(impute_nan=False):\\n\" + IMPUTE_NAN_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Valid formulas: 13116/14704\n",
      "✅ After base descriptor filtering: (13116, 105)\n",
      "🔧 Total chunks: 5\n",
      "🗂️ Output file cleared: valid_descriptor_dataset.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "⚙️ Featurizing:   0%|                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Processing chunk 1 of size 2624\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2edd1d61cce84c219e8bbef82c255dce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ElementProperty:   0%|          | 0/2624 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "327219c02c6646c7b2132a098ce69c27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stoichiometry:   0%|          | 0/2624 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "⚙️ Featurizing:  20%|█████████████▌                                                      | 1/5 [00:09<00:38,  9.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Written chunk 1 to file\n",
      "🔹 Processing chunk 2 of size 2623\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55da8459c6f74381a1fc61f18aea596d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ElementProperty:   0%|          | 0/2623 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9141f7d155b14c42a2e5cca2ac2b7ff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stoichiometry:   0%|          | 0/2623 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "⚙️ Featurizing:  40%|███████████████████████████▏                                        | 2/5 [00:19<00:30, 10.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Written chunk 2 to file\n",
      "🔹 Processing chunk 3 of size 2623\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26350290b12046ff9a1c5ba813aab193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ElementProperty:   0%|          | 0/2623 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d77ef0af1d5f4f91a36e36af57012eef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stoichiometry:   0%|          | 0/2623 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "⚙️ Featurizing:  60%|████████████████████████████████████████▊                           | 3/5 [00:30<00:20, 10.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Written chunk 3 to file\n",
      "🔹 Processing chunk 4 of size 2623\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "922e60b279d0494daa5cdd99c05d15c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ElementProperty:   0%|          | 0/2623 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df0cd882e9354bfd9d531591f180765d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stoichiometry:   0%|          | 0/2623 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "⚙️ Featurizing:  80%|██████████████████████████████████████████████████████▍             | 4/5 [00:45<00:12, 12.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Written chunk 4 to file\n",
      "🔹 Processing chunk 5 of size 2623\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "591c2764efe44aa881c1aef6cfd6ed76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ElementProperty:   0%|          | 0/2623 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca34cd83cf804db38ad63b5cdab76073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stoichiometry:   0%|          | 0/2623 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "⚙️ Featurizing: 100%|████████████████████████████████████████████████████████████████████| 5/5 [01:02<00:00, 12.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Written chunk 5 to file\n",
      "🎉 All chunks complete. Final file saved: valid_descriptor_dataset.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pymatgen.core import Composition\n",
    "from tqdm import tqdm\n",
    "from matminer.featurizers.composition import ElementProperty, Stoichiometry\n",
    "import os\n",
    "\n",
    "# === Step 1: Load Dataset ===\n",
    "try:\n",
    "    df = pd.read_csv(\"composition_enriched_dataset_with_domain_props.csv\")\n",
    "    print(\"✅ Loaded dataset:\", df.shape)\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"❌ Failed to load CSV: {e}\")\n",
    "\n",
    "# === Step 2: Validate and Parse Formulas ===\n",
    "def try_parse_formula(f):\n",
    "    try:\n",
    "        return Composition(f)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "print(\"🔍 Parsing formulas...\")\n",
    "tqdm.pandas()\n",
    "df[\"composition\"] = df[\"Material\"] .progress_apply(try_parse_formula)\n",
    "\n",
    "before = len(df)\n",
    "df = df.dropna(subset=[\"composition\"])\n",
    "after = len(df)\n",
    "print(f\"✅ Valid formulas: {after}/{before}\")\n",
    "\n",
    "print(\"✅ After base descriptor filtering:\", df.shape)\n",
    "\n",
    "# === Step 3: Chunk the Data ===\n",
    "chunks = np.array_split(df, 5)\n",
    "print(f\"🔧 Total chunks: {len(chunks)}\")\n",
    "\n",
    "# === Step 4: Setup Output File ===\n",
    "output_file = \"valid_descriptor_dataset.csv\"\n",
    "if os.path.exists(output_file):\n",
    "    os.remove(output_file)\n",
    "print(f\"🗂️ Output file cleared: {output_file}\")\n",
    "\n",
    "# === Step 5: Setup Featurizers (FAST ONLY FOR DEBUGGING) ===\n",
    "featurizers = [\n",
    "    ElementProperty.from_preset(\"magpie\"),\n",
    "    Stoichiometry()\n",
    "]\n",
    "\n",
    "for f in featurizers:\n",
    "    if hasattr(f, \"set_n_jobs\"):\n",
    "        f.set_n_jobs(1)\n",
    "\n",
    "# === Step 6: Process Each Chunk and Save ===\n",
    "for i, chunk in enumerate(tqdm(chunks, desc=\"⚙️ Featurizing\")):\n",
    "    print(f\"🔹 Processing chunk {i+1} of size {len(chunk)}\")\n",
    "    try:\n",
    "        for f in featurizers:\n",
    "            chunk = f.featurize_dataframe(chunk, \"composition\", ignore_errors=True)\n",
    "        chunk.drop(columns=[\"composition\"], inplace=True)\n",
    "\n",
    "        # Append chunk to file\n",
    "        write_header = not os.path.exists(output_file)\n",
    "        chunk.to_csv(output_file, mode='a', header=write_header, index=False)\n",
    "        print(f\"✅ Written chunk {i+1} to file\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in chunk {i+1}: {e}\")\n",
    "\n",
    "print(\"🎉 All chunks complete. Final file saved:\", output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0bf2574-3b92-42e8-b6bc-6015d135b6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound\n",
    "\n",
    "winsound.Beep(1000, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4224c781-0528-4320-97aa-6d6300326f39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b23f53-c1e7-4dcd-921c-dd3fd780b823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8311936b-0663-4e29-8029-96691edb60d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f5b617-92b9-4dc0-a065-157fec35e320",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0531136-ed9f-4e4c-b5b7-e84319fdc646",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc5d0bb-f6ee-49d4-a541-16d05f7c1b76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
